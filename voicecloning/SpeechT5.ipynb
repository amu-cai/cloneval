{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad2c40f",
   "metadata": {},
   "source": [
    "# Voice Cloning with SpeechT5\n",
    "This notebook walks through the implementation of a voice cloning algorithm using the SpeechT5 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf34ae",
   "metadata": {},
   "source": [
    "# Importing Libraries and Preparing the Project\n",
    "\n",
    "This section initializes the project by importing essential libraries and modules. It sets up a logger to display runtime information and creates the required directories (`original_samples` and `cloned_samples`) for storing original and cloned audio samples. Additionally, it ensures the determinism of the model by enabling deterministic operations and setting a fixed random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import write\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from transformers import set_seed\n",
    "from speechbrain.pretrained.interfaces import EncoderClassifier\n",
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "\n",
    "# Set up determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "set_seed(42)\n",
    "\n",
    "# Set up logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(levelname)s | %(asctime)s | %(message)s', level=logging.INFO)\n",
    "\n",
    "# Create required directories\n",
    "if not os.path.isdir('original_samples'):\n",
    "    os.makedirs('original_samples', exist_ok=True)\n",
    "    logger.info('Created directory: original_samples')\n",
    "\n",
    "if not os.path.isdir('cloned_samples'):\n",
    "    os.makedirs('cloned_samples', exist_ok=True)\n",
    "    logger.info('Created directory: cloned_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee172d",
   "metadata": {},
   "source": [
    "# Set Up Dataset and Prompts\n",
    "\n",
    "This section loads the LibriSpeech dataset in streaming mode, focusing on the test.clean split. It initializes key variables related to dataset processing. It reads a CSV file containing text prompts that map audio sample IDs to their corresponding cloning text and reference IDs for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the computation device: GPU ('cuda:0') if available, otherwise CPU.\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Defines column names in the dataset:\n",
    "audio_column = 'audio'        # Contains audio data.\n",
    "text_column = 'text'          # Contains text prompts.\n",
    "speaker_column = 'speaker_id' # Contains unique speaker identifiers.\n",
    "id_column = 'id'              # Contains unique sample identifiers.\n",
    "\n",
    "# Loads the LibriSpeech dataset in streaming mode, focusing on the 'test.clean' split. The `trust_remote_code` flag enables custom dataset scripts.\n",
    "dataset = load_dataset('openslr/librispeech_asr', split='test.clean', streaming=True, trust_remote_code=True)\n",
    "\n",
    "# Reads a CSV file with mapping sample IDs to their cloning text and reference IDs for comparison.\n",
    "prompts = pd.read_csv(f'../data/text_prompts/ls-test-clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeacb0c",
   "metadata": {},
   "source": [
    "# Initialize Models and Tools\n",
    "\n",
    "This section initializes the necessary models and tools for text-to-speech cloning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker classifier for embedding extraction\n",
    "classifier = EncoderClassifier.from_hparams(\n",
    "    source='speechbrain/spkrec-xvect-voxceleb',\n",
    "    run_opts={\"device\": device},\n",
    "    savedir=os.path.join('/tmp', 'speechbrain/spkrec-xvect-voxceleb')\n",
    ")\n",
    "# Processor for handling inputs to the model\n",
    "processor = SpeechT5Processor.from_pretrained('microsoft/speecht5_tts')\n",
    "# Text-to-speech model\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained('microsoft/speecht5_tts').to(device)\n",
    "# HiFi-GAN vocoder for audio post-processing\n",
    "vocoder = SpeechT5HifiGan.from_pretrained('microsoft/speecht5_hifigan').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a354b70",
   "metadata": {},
   "source": [
    "# Define Cloning Function\n",
    "\n",
    "This section defines the clone_speecht5 function, which clones an audio sample based on a provided text prompt. It extracts normalized speaker embeddings, processes the text input into tokens, and generates synthetic audio using the SpeechT5 model and vocoder. The function returns the cloned audio and its sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_speecht5(model_input_audio, model_input_text_prompt): \n",
    "    # Extract speaker embeddings\n",
    "    speaker_embeddings = classifier.encode_batch(model_input_audio)\n",
    "    speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
    "    speaker_embeddings = speaker_embeddings[0].view(1, -1)\n",
    "\n",
    "    # Process the text prompt\n",
    "    inputs = processor(text=model_input_text_prompt, return_tensors='pt').to(device)\n",
    "\n",
    "    # Generate synthetic audio\n",
    "    cloned_audio = model.generate_speech(inputs['input_ids'], speaker_embeddings, vocoder=vocoder)\n",
    "    cloned_audio = cloned_audio.view(-1).cpu().numpy()\n",
    "    cloned_sampling_rate = 16000\n",
    "    return cloned_audio, cloned_sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deebcded",
   "metadata": {},
   "source": [
    "# Iterate Over Dataset Samples\n",
    "\n",
    "This section processes each sample from the dataset by extracting the audio and the associated text prompt for cloning. It retrieves a reference sample for comparison based on the id_sample_to_compare field and saves the reference audio in the original_samples directory. The clone_speecht5 function is then used to generate cloned audio, which is saved in the cloned_samples directory. For each successfully cloned sample, a log entry is created to confirm the operation. The loop is configured to stop after processing five samples to limit runtime during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracks the current loop iteration\n",
    "current_iteration = 0\n",
    "\n",
    "for sample in tqdm(dataset):\n",
    "    # Prepare file name for saving the cloned audio\n",
    "    filename = f'{sample[speaker_column]}_{sample[id_column]}.wav'\n",
    "    \n",
    "    # Get the text prompt associated with the current sample\n",
    "    model_input_text_prompt = prompts.loc[\n",
    "        prompts['id_sample_to_clone'] == sample[id_column],\n",
    "        'text'\n",
    "    ].values[0]\n",
    "    \n",
    "    # Extract the audio data to be cloned and move it to the appropriate device\n",
    "    model_input_audio = torch.tensor(sample[audio_column]['array']).to(device)\n",
    "    \n",
    "    # Get the ID of the sample to compare against for reference audio\n",
    "    id_sample_to_compare = prompts.loc[\n",
    "        prompts['id_sample_to_clone'] == sample[id_column],\n",
    "        'id_sample_to_compare'\n",
    "    ].values[0]\n",
    "\n",
    "    # Retrieve the reference sample from the dataset based on the comparison ID\n",
    "    for proposed_sample_to_compare in dataset:\n",
    "        if proposed_sample_to_compare[id_column] == id_sample_to_compare:\n",
    "            sample_to_compare = proposed_sample_to_compare\n",
    "    \n",
    "    # Extract the reference audio and its sampling rate\n",
    "    audio_to_compare = sample_to_compare[audio_column]['array']\n",
    "    sampling_rate_to_compare = sample_to_compare[audio_column]['sampling_rate']\n",
    "    \n",
    "    # Save the reference audio to the 'original_samples' directory\n",
    "    write(f'original_samples/{filename}', sampling_rate_to_compare, audio_to_compare)\n",
    "\n",
    "    # Clone the audio using the text prompt and save it to the 'cloned_samples' directory\n",
    "    cloned_audio, cloned_sampling_rate = clone_speecht5(model_input_audio, model_input_text_prompt)\n",
    "    write(f'cloned_samples/{filename}', cloned_sampling_rate, cloned_audio)\n",
    "\n",
    "    # Information about properly cloned sample\n",
    "    logger.info(f'\\nSample {filename} cloned properly')\n",
    "\n",
    "    # Ends the loop when iteration reaches 5\n",
    "    current_iteration += 1\n",
    "    if current_iteration == 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
