{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad2c40f",
   "metadata": {},
   "source": [
    "# Voice Cloning with SpeechT5\n",
    "This notebook walks through the implementation of a voice cloning algorithm using the SpeechT5 model. It loads a dataset, processes audio and text, and generates cloned audio samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf34ae",
   "metadata": {},
   "source": [
    "## Step 1: Import Necessary Libraries\n",
    "We begin by importing all the necessary libraries for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import write\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import argparse\n",
    "from transformers import set_seed\n",
    "\n",
    "# Configure logging to display detailed output\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(levelname)s | %(asctime)s | %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f65d5a",
   "metadata": {},
   "source": [
    "## Step 2: Define the Voice Cloning Algorithm\n",
    "The main logic of the algorithm is encapsulated in the `VoiceCloner` class. This class provides methods for:\n",
    "1. **Loading the dataset**: Filters out unnecessary columns and keeps only relevant information (audio, text, speaker ID, and sample ID).\n",
    "2. **Initializing SpeechT5**: Sets up the speech synthesis model, including a processor, TTS model, and vocoder.\n",
    "3. **Voice Cloning**: Generates synthetic audio using the SpeechT5 model based on input audio and text prompts.\n",
    "4. **Generating Outputs**: Processes each dataset entry to create cloned audio samples and saves them as WAV files.\n",
    "\n",
    "### Class Initialization\n",
    "The class is initialized with the dataset and SpeechT5 model setup.\n",
    "\n",
    "#### Arguments:\n",
    "- **`dataset_name`**: Name of the Hugging Face dataset to load.\n",
    "- **`split_name`**: The dataset split to use (e.g., test.clean).\n",
    "- **`cache_dir`**: Directory for caching datasets.\n",
    "- **`audio_column`**: Column name for audio data.\n",
    "- **`text_column`**: Column name for text prompts.\n",
    "- **`speaker_column`**: Column name for speaker identifiers.\n",
    "- **`id_column`**: Column name for unique sample identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47564994",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceCloner:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name: str,\n",
    "        split_name: str,\n",
    "        cache_dir: str,\n",
    "        audio_column: str,\n",
    "        text_column: str,\n",
    "        speaker_column: str,\n",
    "        id_column: str,\n",
    "    ) -> None:\n",
    "        self.device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.audio_column = audio_column\n",
    "        self.text_column = text_column\n",
    "        self.speaker_column = speaker_column\n",
    "        self.id_column = id_column\n",
    "        self.dataset = self._load_dataset(dataset_name, split_name, cache_dir)\n",
    "        self.prompts = pd.read_csv(f'../data/text_prompts/ls-test-clean.csv')\n",
    "        \n",
    "        logger.info(f'Initializing SpeechT5 model')\n",
    "        self._init_speecht5()\n",
    "        self._clone = self._clone_speecht5\n",
    "        \n",
    "    def _load_dataset(self, dataset_name: str, split_name: str, cache_dir: str) -> Dataset:\n",
    "        logger.info(f'Loading {split_name} split of {dataset_name} dataset')\n",
    "        dataset = load_dataset(dataset_name, split=split_name, cache_dir=cache_dir, trust_remote_code=True)\n",
    "        \n",
    "        # Check for necessary columns\n",
    "        required_columns = [self.audio_column, self.text_column, self.speaker_column, self.id_column]\n",
    "        for col in required_columns:\n",
    "            if col not in dataset.column_names:\n",
    "                raise ValueError(f'Required column {col} not found in dataset.')\n",
    "        \n",
    "        # Remove unnecessary columns\n",
    "        to_remove = [c for c in dataset.column_names if c not in required_columns]\n",
    "        dataset = dataset.remove_columns(to_remove)\n",
    "        logger.info(f'Removed columns: {to_remove}')\n",
    "        return dataset\n",
    "\n",
    "    def _init_speecht5(self) -> None:\n",
    "        from speechbrain.pretrained.interfaces import EncoderClassifier\n",
    "        from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "        \n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        set_seed(42)\n",
    "        \n",
    "        # Speaker classifier for embedding extraction\n",
    "        self.classifier = EncoderClassifier.from_hparams(\n",
    "            source='speechbrain/spkrec-xvect-voxceleb',\n",
    "            run_opts={\"device\": self.device},\n",
    "            savedir=os.path.join('/tmp', 'speechbrain/spkrec-xvect-voxceleb')\n",
    "        )\n",
    "        # Processor for handling inputs to the model\n",
    "        self.processor = SpeechT5Processor.from_pretrained('microsoft/speecht5_tts')\n",
    "        # Text-to-speech model\n",
    "        self.model = SpeechT5ForTextToSpeech.from_pretrained('microsoft/speecht5_tts').to(self.device)\n",
    "        # HiFi-GAN vocoder for audio post-processing\n",
    "        self.vocoder = SpeechT5HifiGan.from_pretrained('microsoft/speecht5_hifigan').to(self.device)\n",
    "\n",
    "    def _clone_speecht5(self, audio: torch.Tensor, text_prompt: str) -> Tuple[np.ndarray, int]:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        set_seed(42)\n",
    "        \n",
    "        # Extract speaker embeddings\n",
    "        speaker_embeddings = self.classifier.encode_batch(audio)\n",
    "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
    "        speaker_embeddings = speaker_embeddings[0].view(1, -1)\n",
    "        \n",
    "        # Process the text prompt\n",
    "        inputs = self.processor(text=text_prompt, return_tensors='pt').to(self.device)\n",
    "        \n",
    "        # Generate synthetic audio\n",
    "        cloned_audio = self.model.generate_speech(inputs['input_ids'], speaker_embeddings, vocoder=self.vocoder)\n",
    "        return (cloned_audio.view(-1).cpu().numpy(), 16_000)\n",
    "    \n",
    "    def generate(self):\n",
    "        for sample in tqdm(self.dataset):\n",
    "            # Prepare file name for saving the cloned audio\n",
    "            filename = f'{sample[self.speaker_column]}_{sample[self.id_column]}.wav'\n",
    "            \n",
    "            # Get the text prompt associated with the current sample\n",
    "            text_prompt = self.prompts.loc[\n",
    "                self.prompts['id_sample_to_clone'] == sample[self.id_column],\n",
    "                'text'\n",
    "            ].values[0]\n",
    "            \n",
    "            # Extract the audio data to be cloned and move it to the appropriate device\n",
    "            audio_to_clone = torch.tensor(sample[self.audio_column]['array']).to(self.device)\n",
    "            \n",
    "            # Get the ID of the sample to compare against for reference audio\n",
    "            id_to_compare = self.prompts.loc[\n",
    "                self.prompts['id_sample_to_clone'] == sample[self.id_column],\n",
    "                'id_sample_to_compare'\n",
    "            ].values[0]\n",
    "\n",
    "            # Retrieve the reference sample from the dataset based on the comparison ID\n",
    "            sample_to_compare = self.dataset.filter(\n",
    "                lambda example: example[self.id_column] == id_to_compare\n",
    "            )[0]\n",
    "            \n",
    "            # Extract the reference audio and its sampling rate\n",
    "            audio_to_compare = sample_to_compare[self.audio_column]['array']\n",
    "            sampling_rate_to_compare = sample_to_compare[self.audio_column]['sampling_rate']\n",
    "            \n",
    "            # Save the reference audio to the 'original_samples' directory\n",
    "            write(f'original_samples/{filename}', sampling_rate_to_compare, audio_to_compare)\n",
    "\n",
    "            # Clone the audio using the text prompt and save it to the 'cloned_samples' directory\n",
    "            cloned_audio, cloned_sampling_rate = self._clone(audio_to_clone, text_prompt)\n",
    "            write(f'cloned_samples/{filename}', cloned_sampling_rate, cloned_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89694b79",
   "metadata": {},
   "source": [
    "## Step 3: Parse Script Arguments\n",
    "This function defines the arguments required to run the script, such as dataset name, split, and cache directory.\n",
    "\n",
    "By default, the script is configured to clone samples from the LibriSpeech test-clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58fc5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset_name', type=str, default='openslr/librispeech_asr')\n",
    "    parser.add_argument('--split_name', type=str, default='test.clean')\n",
    "    parser.add_argument('--cache_dir', type=str, default=None)\n",
    "    parser.add_argument('--audio_column', type=str, default='audio')\n",
    "    parser.add_argument('--text_column', type=str, default='text')\n",
    "    parser.add_argument('--speaker_column', type=str, default='speaker_id')\n",
    "    parser.add_argument('--id_column', type=str, default='id')\n",
    "\n",
    "    # This line ensures the script works in Jupyter Notebook by ignoring extra arguments \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504327ac",
   "metadata": {},
   "source": [
    "## Step 4: Main Function\n",
    "The main function initializes the `VoiceCloner` class and starts the cloning process for all dataset entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args: argparse.Namespace):\n",
    "    if not os.path.isdir('original_samples'):\n",
    "        os.makedirs('original_samples', exist_ok=True)\n",
    "        logger.info('Created directory: original_samples')\n",
    "        \n",
    "    if not os.path.isdir('cloned_samples'):\n",
    "        os.makedirs('cloned_samples', exist_ok=True)\n",
    "        logger.info('Created directory: cloned_samples')\n",
    "\n",
    "    if not os.path.isdir(args.cache_dir):\n",
    "        os.makedirs(args.cache_dir, exist_ok=True)\n",
    "        logger.info(f'Created directory: {args.cache_dir}')\n",
    "\n",
    "    logger.info(f'Voice cloning arguments: [{args}]')\n",
    "    voice_cloner = VoiceCloner(\n",
    "        args.dataset_name,\n",
    "        args.split_name,\n",
    "        args.cache_dir,\n",
    "        args.audio_column,\n",
    "        args.text_column,\n",
    "        args.speaker_column,\n",
    "        args.id_column,\n",
    "    )\n",
    "    voice_cloner.generate()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
